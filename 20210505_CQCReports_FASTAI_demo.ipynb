{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20210505 CQCReports FASTAI demo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "y-qDqFG-ZCRL"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83IdTlP72zCq",
        "outputId": "ecc32532-ffdc-476d-e528-7619287095c3"
      },
      "source": [
        "# set_up notebook\n",
        "# run on google colab to access the GPU processing.\n",
        "!pip install utils\n",
        "!pip install fastcore\n",
        "!pip install fastai==2.3.0\n",
        "\n",
        "import fastai\n",
        "from fastai.text.all import *\n",
        "from fastcore.foundation import L\n",
        "from utils import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting utils\n",
            "  Downloading https://files.pythonhosted.org/packages/55/e6/c2d2b2703e7debc8b501caae0e6f7ead148fd0faa3c8131292a599930029/utils-1.0.1-py2.py3-none-any.whl\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n",
            "Collecting fastcore\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b0/f1fbf554e0bf3c76e1bdc3b82eedfe41fcf656479586be38c64421082b1b/fastcore-1.3.20-py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastcore) (19.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastcore) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastcore) (2.4.7)\n",
            "Installing collected packages: fastcore\n",
            "Successfully installed fastcore-1.3.20\n",
            "Collecting fastai==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/53/edf39e15b7ec5e805a0b6f72adbe48497ebcfa009a245eca7044ae9ee1c6/fastai-2.3.0-py3-none-any.whl (193kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.0) (1.0.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.0) (19.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.0) (3.13)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.0) (0.22.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.0) (2.23.0)\n",
            "Collecting torch<1.8,>=1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 22kB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.0) (20.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.0) (7.1.2)\n",
            "Collecting torchvision<0.9,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/df/969e69a94cff1c8911acb0688117f95e1915becc1e01c73e7960a2c76ec8/torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 35kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.0) (2.2.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.0) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.0) (1.1.5)\n",
            "Requirement already satisfied: fastcore<1.4,>=1.3.8 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.0) (1.3.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fastprogress>=0.2.4->fastai==2.3.0) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai==2.3.0) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.3.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.3.0) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.8,>=1.7.0->fastai==2.3.0) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai==2.3.0) (2.4.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.0) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.0) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.0) (56.1.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.0) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.0) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.0) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.0) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.0) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.0) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.0) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.0) (1.0.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.3.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.3.0) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.3.0) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==2.3.0) (2018.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3->fastai==2.3.0) (3.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->fastai==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3->fastai==2.3.0) (3.4.1)\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision, fastai\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "  Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "Successfully installed fastai-2.3.0 torch-1.7.1 torchvision-0.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaqVCFLDwF83"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "import requests\n",
        "from collections import OrderedDict\n",
        "import json"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCrAN06y3Lhw",
        "outputId": "fcb2d485-6594-434e-ce09-93354b672f1e"
      },
      "source": [
        "#set up folders \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "root_dir = 'drive/My Drive/Colab Notebooks/'\n",
        "\n",
        "# Here is where you'll need to update to point to any specific folders you create. We only use these to store the API reports. \n",
        "base_dir = root_dir + 'files'\n",
        "reports_dir = base_dir + \"/Reports\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkaZ-Kq13MVT"
      },
      "source": [
        "# Create functions\n",
        "# Functions to connect to CQC API and retreive Inspection Reports.\n",
        "\n",
        "# First step is to get the location ids\n",
        "def get_location_ids(records):\n",
        "    r = requests.get(\"https://api.cqc.org.uk/public/v1/locations?page=1&perPage=\"+str(records))   \n",
        "    if r.status_code == 200:\n",
        "        txt = json.loads(r.content)\n",
        "        df = pd.DataFrame(txt[\"locations\"])\n",
        "    else:\n",
        "        return(\"Http request not successful\")\n",
        "    return(df)\n",
        "\n",
        "# \n",
        "def get_location_details(ids):\n",
        "  req_string = \"https://api.cqc.org.uk/public/v1/locations/\" + ids\n",
        "  df = pd.DataFrame()\n",
        "\n",
        "  for i, string in enumerate(req_string):\n",
        "    r = requests.get(string)\n",
        "    txt = json.loads(r.content)\n",
        "    row = pd.json_normalize(txt)\n",
        "    df = df.append(row, ignore_index=True)\n",
        "    \n",
        "  return(df)\n",
        "\n",
        "# get report text\n",
        "def get_report_text(reportid):\n",
        "\n",
        "  req_string = \"https://api.cqc.org.uk/public/v1/reports/\" + reportid\n",
        "  r = requests.get(req_string, headers = {\"Accept\":\"text/plain\"})\n",
        "  report_txt = r.content\n",
        "\n",
        "  return(report_txt)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jas5dgHM5Fko",
        "outputId": "0e6da22e-3baa-4b30-916b-5be1f8b8a29b"
      },
      "source": [
        "# Use the API functions to extract data from CQCs API\n",
        "loc_df = get_location_ids(10000)\n",
        "deets_df = get_location_details(loc_df.iloc[:,0])\n",
        "reports_df = deets_df.dropna(subset = [\"currentRatings.overall.reportLinkId\"])\n",
        "reports_df[\"text\"] = reports_df.apply(lambda row: get_report_text(row[\"currentRatings.overall.reportLinkId\"]), axis = 1)\n",
        "# file tends to be stored as byte string (i.e. prefixed with b) below decodes the byte string.\n",
        "reports_df['text'] = reports_df['text'].str.decode(encoding=\"utf-8\", errors=\"ignore\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GofoUc8zw25o"
      },
      "source": [
        "# Save out a parquet so we don't have to keep hitting the API. \n",
        "#reports_df.to_pickle(reports_dir+\"/20210507 Reports Data.pkl\")\n",
        "reports_df = pd.read_pickle(reports_dir+\"/20210507 Reports Data.pkl\")"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-02s_qvyKgYJ",
        "outputId": "fb2651d9-9e3f-4dc0-f2ea-ff1d82371f9c"
      },
      "source": [
        "# Here we just take a small subset for speed. Colab has run time limits and to run\n",
        "# on the full data set would take too long. I've kept the large dataset in the process\n",
        "# incase you have access to better GPU compute options. \n",
        "reports_df.reset_index()\n",
        "reports_df = reports_df.iloc[0:400,:]\n",
        "reports_df.shape"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 57)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PafzvEyx29E2"
      },
      "source": [
        "# Creating a language Model with Transfer Learning (FastAI)\n",
        "Now that we have our data we can use the free text in the inspection reports to train a language model. \n",
        "\n",
        "Creating Language Models from scratch is time consuming, requires huge amounts of data/compute and can often require us to create additional text files designed around teaching specific \"rules\" to the language. \n",
        "\n",
        "It is often much better to take a langauge model that already understands the basic concepts of the language you are working in (i.e. English) and then tweak it to understand the specific domain you are working on. That way you don't have to teach it English, you only have to teach the model the subject matter / domain. This use of a general model and tweaking it to your domain is called Transfer Learning and it can really speed up the process of developing language models.\n",
        "\n",
        "FastAI provides some really convienient wrappers around the different stages of the process making it really simple to apply transfer learning. There are several, high and mid level APIs (read the docs) but for simplicity we are going to show the following:\n",
        "\n",
        "  - Dataloaders - used for loading the data read to be fed into our model.\n",
        "  - Learners - used for training the model. \n",
        "\n",
        "Lets use our reports text to build ontop of a pre-build lanaguage model\n",
        "\n",
        "# The humble DataBlock\n",
        "First lets create a DataBlock a sort of template for how we want to read in our data\n",
        "\n",
        "Notice the following:\n",
        "  - we are using TextBlock.from_df because our format is a pandas df and we are reading text. There are a number of different block types so you can load from files, you can even add custom functions to extract dataas you need. \n",
        "  - secondly we have is_lm = TRUE this means it is going to try and classify\n",
        "The next word in sequence as opposed to requiring us to provide a specific classification to the model. (just a conveient wrapper internally it is still a classification task i.e. given this squence what is the next word)\n",
        "  - We use get_items to specify where in our dataframe to look for the text. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je8swaqCw9Bo"
      },
      "source": [
        "# first build the data block\n",
        "reports_datab = DataBlock(blocks=TextBlock.from_df('text', is_lm = True),\n",
        "                    get_items=ColReader('text'))"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_a-Iqoj88_a"
      },
      "source": [
        "The next step is to use our \"template\" datablock as instructions to read in our data. \n",
        "\n",
        "# Data loaders\n",
        "To do this within the FASTAI api we use a dataloader. bs = batch size and seq_len = sequence length. These arguments just support chunking up the text. I probably need to explore the impact of tweaking these further but for now they are not particularly important to generating our language model.\n",
        "\n",
        "The key thing is the dataloader handles creating the training test and validation sets from the data provided. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52N2cdBx88Le"
      },
      "source": [
        "# next use the data block \n",
        "reports_dls_lm = reports_datab.dataloaders(reports_df, bs = 128, seq_len = 80)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4dhs718E67C"
      },
      "source": [
        "Lets take a look at at the first two pieces of text we've loaded. There are few automated preprocessing steps that have been taken, mostly tokenisation and some string replacements. The string replacements are indicated by the xx prefix. so xxbos symbolised the begining of a string xxunk is a replacement for very low frequency words. xxrep indicates a repeating pattern etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "SJyqw8l3FEyt",
        "outputId": "d1846d8a-007d-4c16-c607-563a77c02f12"
      },
      "source": [
        "reports_dls_lm.show_batch(max_n = 2)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos 1 xxmaj progressive xxmaj mews xxmaj inspection report 30 xxmaj january 2017 \\n xxmaj homes xxunk xxmaj care xxmaj limited \\n xxmaj progressive xxmaj mews \\n xxmaj inspection report \\n xxmaj xxunk xxmaj road \\n xxmaj eight xxmaj xxunk xxmaj green \\n xxmaj xxunk \\n xxmaj essex \\n xxup xxunk xxunk \\n xxmaj tel : xxunk \\n xxmaj date of inspection visit : \\n 16 xxmaj november 2016 \\n xxmaj date of publication : \\n 30 xxmaj january 2017</td>\n",
              "      <td>1 xxmaj progressive xxmaj mews xxmaj inspection report 30 xxmaj january 2017 \\n xxmaj homes xxunk xxmaj care xxmaj limited \\n xxmaj progressive xxmaj mews \\n xxmaj inspection report \\n xxmaj xxunk xxmaj road \\n xxmaj eight xxmaj xxunk xxmaj green \\n xxmaj xxunk \\n xxmaj essex \\n xxup xxunk xxunk \\n xxmaj tel : xxunk \\n xxmaj date of inspection visit : \\n 16 xxmaj november 2016 \\n xxmaj date of publication : \\n 30 xxmaj january 2017 \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>prior to being sent to a dental laboratory \\n and before treatment was completed . \\n xxmaj the practice had procedures to reduce the possibility of \\n xxmaj legionella or other bacteria developing in the water \\n systems , in line with a risk assessment . xxmaj all \\n recommendations had been actioned and records of water \\n testing and dental unit water line management were in \\n place . \\n xxmaj we saw cleaning schedules for the premises .</td>\n",
              "      <td>to being sent to a dental laboratory \\n and before treatment was completed . \\n xxmaj the practice had procedures to reduce the possibility of \\n xxmaj legionella or other bacteria developing in the water \\n systems , in line with a risk assessment . xxmaj all \\n recommendations had been actioned and records of water \\n testing and dental unit water line management were in \\n place . \\n xxmaj we saw cleaning schedules for the premises . xxmaj</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrN1ow-6FNWo"
      },
      "source": [
        "# Training a Language Model\n",
        "Now that we've looked at the text lets start to train our model. \n",
        "\n",
        "The first thing we need to do is to create a \"learner\". FASTAI has a built in language learner so we can easily build our language model. in this case we provide it with 3 key arguments:\n",
        "\n",
        "  - First we give it our \"loaded\" data loader\n",
        "  - Secondly we give it a \"model\" here we give it a prebuilt pytorch model based on LSTMs trained on wikipedia. However, you can contruct your own architecture's using pytorch and put that here. \n",
        "  - thirdly metrics a dict of methods to output for you the user to see performance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD6diUirH60Q"
      },
      "source": [
        "learn = language_model_learner(\n",
        "    reports_dls_lm, AWD_LSTM, drop_mult= 0.3,\n",
        "    metrics = [accuracy, Perplexity()]).to_fp16()"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvH3F0fjJ9eu"
      },
      "source": [
        "To begin with we can run a a single pass over the model only training the top layer this helps the align the final prediction layer to the pre-build model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "aXFxGHXhKxLm",
        "outputId": "9e577c8d-65ea-438a-9afc-a6c9e2b79be6"
      },
      "source": [
        "learn.fit_one_cycle(1)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.111483</td>\n",
              "      <td>3.884032</td>\n",
              "      <td>0.309200</td>\n",
              "      <td>48.619869</td>\n",
              "      <td>45:52</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHGMvaUBK2zW"
      },
      "source": [
        "We can then unfreeze the the lower levels of the model and train the whole thing. Because we aligned the top layer retraining the whole model should retain much of the understanding encoded in the pre-built model only updating where it can to improve predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "kf-QLfqIJ6-i",
        "outputId": "a20d6bc7-69ef-433a-d437-a6adf1118591"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(3, 2e-3)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.566002</td>\n",
              "      <td>2.292500</td>\n",
              "      <td>0.509435</td>\n",
              "      <td>9.899653</td>\n",
              "      <td>46:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.073258</td>\n",
              "      <td>2.036916</td>\n",
              "      <td>0.559299</td>\n",
              "      <td>7.666928</td>\n",
              "      <td>45:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.863051</td>\n",
              "      <td>1.995046</td>\n",
              "      <td>0.568259</td>\n",
              "      <td>7.352542</td>\n",
              "      <td>45:23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7QP5FpbLNGR"
      },
      "source": [
        "By taking this staggard approach to updating the pre-trained model to our new domain, we can ensure that lots of the general learning we've taken from the prebuilt model is retained and should allow us train a decent langauge model that is trained to our domain but able to generalise well.\n",
        "\n",
        "Now we have our model we can have a little play. Through doing this we can get a sense of what the model \"thinks\" and whether it understands our domain. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "wcjk6jTGP1pJ",
        "outputId": "71dc9508-1e16-4fc2-8a7f-2e066c135a11"
      },
      "source": [
        "TEXT = \"The service must\"\n",
        "N_words = 50\n",
        "N_sentences = 3\n",
        "preds = [learn.predict(TEXT, N_words, temperature= 0.75) for _ in range(N_sentences)]\n",
        "\n",
        "print('\\n'.join(preds))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The service must make the Mental Capacity Act 2005 ( mca ) . It introduces \n",
            " legal requirements to make sure that people who lack the capacity to make decisions about their \n",
            " care and treatment can only be deprived of their liberty to receive care and treatment when\n",
            "The service must have been met by the registered manager \n",
            " The Registered Manager and Registered Manager had overall responsibility for the \n",
            " management and management of the service . \n",
            " This was a large amount of time for people receiving the service . The \n",
            "\n",
            "The service must enable people to be involved in decisions about their care \n",
            " and treatment . The registered manager confirmed that this would be taken into \n",
            " consideration . \n",
            " Are services well - led ? \n",
            " We found that this practice was providing well - led care in\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "630cY7_HVwPR"
      },
      "source": [
        "Now that we've build our model and are happy with it, we can now save the model. For our use case (i.e. classifiers) we don't want the full model but instead we want everything but the last layer (i.e. the word prediction layer). What we can do is detatch the last layer and save that model. This is referred to in the documentation as the \"encoder\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSeQ0TsyW2If"
      },
      "source": [
        "# set the model path and then save\n",
        "learn.path = Path(reports_dir)\n",
        "learn.save_encoder(\"reports_lm\")"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiTG2L-RQqsH"
      },
      "source": [
        "# Using our language model\n",
        "\n",
        "Now that we have a language model that \"understands\" CQC reports we can use this model for different tasks. In our case we looking to generate a number of text classifiers looking at CQC reports. The value here is that we can train the classifiers ontop of the language model. in the interest of time we will only build one classifier identifying the locations \"sector\" but this template serves as a model that allows us to build any number of classifiers. \n",
        "\n",
        "Lets start by creating the DataBlock and loader for our classifier. Which will try and classifier the overall rating of the report based on the text. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJSnimcgVyNI"
      },
      "source": [
        "# Now we've trained the language model we can look to train on more of our original data.\n",
        "# be cause we are only doing one prediction per record it is much faster than language modelling which goes\n",
        "# through each piece of text in a moving window. \n",
        "# So lets reimport our original dataset\n",
        "reports_df = pd.read_pickle(reports_dir+\"/20210507 Reports Data.pkl\")\n",
        "# To simplify again we can create a binary classification task\n",
        "# Good and outstanding = good\n",
        "reports_df[\"isgood\"] = reports_df[\"currentRatings.overall.rating\"].isin([\"Good\", \"Outstanding\"])"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "OTZzGJ0PZslJ",
        "outputId": "5276df46-e0d3-420d-9769-3e2bf4001b1a"
      },
      "source": [
        "# lets start with creating the datablock and loading the data\n",
        "clas_block = DataBlock(\n",
        "    blocks = (TextBlock.from_df('text', vocab = reports_dls_lm.vocab), CategoryBlock),\n",
        "    get_x = ColReader('text'),\n",
        "    get_y = ColReader('isgood'),\n",
        "    splitter = RandomSplitter(0.2)\n",
        ")\n",
        "# and loading the data\n",
        "dls_clas = clas_block.dataloaders(reports_df, bs = 128, seq_len = 80)\n",
        "\n",
        "# we can take a quick peak at the data being fed into the classifier\n",
        "dls_clas.show_batch(max_n = 3)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj this report describes our judgement of the quality of care at this location . xxmaj it is based on a combination of what we \\n found when we inspected and a review of all information available to xxup cqc including information given to us from \\n patients , the public and other organisations \\n xxmaj ratings \\n xxmaj overall rating for this location xxmaj good xxrep 3 – \\n xxmaj are services safe ? xxmaj good xxrep 3 – \\n xxmaj are services effective ? xxmaj good xxrep 3 – \\n xxmaj are services caring ? xxmaj good xxrep 3 – \\n xxmaj are services responsive ? xxmaj good xxrep 3 – \\n xxmaj are services well - led ? xxmaj good xxrep 3 – \\n xxmaj mental xxmaj health xxmaj act responsibilities and xxmaj mental xxmaj capacity xxmaj act and xxmaj deprivation of xxmaj liberty \\n xxmaj</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xxbos xxmaj this report describes our judgement of the quality of care at this location . xxmaj it is based on a combination of what we \\n found when we inspected and a review of all information available to xxup cqc including information given to us from \\n patients , the public and other organisations \\n xxmaj ratings \\n xxmaj overall rating for this location xxmaj good xxrep 3 – \\n xxmaj are services safe ? xxmaj good xxrep 3 – \\n xxmaj are services effective ? xxmaj good xxrep 3 – \\n xxmaj are services caring ? xxmaj good xxrep 3 – \\n xxmaj are services responsive ? xxmaj good xxrep 3 – \\n xxmaj are services well - led ? xxmaj good xxrep 3 – \\n xxmaj mental xxmaj health xxmaj act responsibilities and xxmaj mental xxmaj capacity xxmaj act and xxmaj deprivation of xxmaj liberty \\n xxmaj</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xxbos xxmaj this report describes our judgement of the quality of care at this location . xxmaj it is based on a combination of what we \\n found when we inspected and a review of all information available to xxup cqc including information given to us from \\n patients , the public and other organisations \\n xxmaj ratings \\n xxmaj overall rating for this location xxmaj good xxrep 3 – \\n xxmaj are services safe ? xxmaj good xxrep 3 – \\n xxmaj are services effective ? xxmaj good xxrep 3 – \\n xxmaj are services caring ? xxmaj good xxrep 3 – \\n xxmaj are services responsive ? xxmaj good xxrep 3 – \\n xxmaj are services well - led ? xxmaj good xxrep 3 – \\n xxmaj overall summary \\n xxmaj xxunk xxmaj hospital is operated by xxmaj nuffield xxmaj health . xxmaj the \\n hospital has 49</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuTd1MPzjaDC"
      },
      "source": [
        "Once we have the loader we can build the learner. You'll notice we use the same model architecture (AWD_LSTM) this means we can update the weights with our pretrained language model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuriUn3_fLnu"
      },
      "source": [
        "learner_clas = text_classifier_learner(dls_clas,\n",
        "                                       AWD_LSTM,\n",
        "                                       drop_mult=0.5,\n",
        "                                       metrics = [accuracy, Perplexity()]).to_fp16()"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EVcU925rNhw"
      },
      "source": [
        "So let set the path for our learner (so it can find our pretrained encoder we saved earlier) and then load that encoder. This updates all the AWD_LSTM based on the reports_language model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuL1lSPXnJz2",
        "outputId": "c4061a45-1199-4402-bb11-a12ff3ff1b92"
      },
      "source": [
        "learner_clas.path = Path(reports_dir)\n",
        "learner_clas.load_encoder(\"reports_lm\")"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai.text.learner.TextLearner at 0x7f190d7abf50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDgn6HC9r-DS"
      },
      "source": [
        "Like before when we first load a model everything apart fomr the head is frozen. We can start by training the head, to classify our reports for one cycle. This gives it a baseline understanding of how to use the language model to predict the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "yqUtlikknPKT",
        "outputId": "12b679f3-5c32-41b0-94fe-96732d074acc"
      },
      "source": [
        "learner_clas.fit_one_cycle(1)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.390697</td>\n",
              "      <td>0.395719</td>\n",
              "      <td>0.894910</td>\n",
              "      <td>1.485452</td>\n",
              "      <td>03:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imgOaQzBsdKB"
      },
      "source": [
        "We can then unfreeze the final 2 layers and train again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "rjDYVqWdnWEC",
        "outputId": "a3986e21-b2bf-47c2-b00f-465a59c79b3e"
      },
      "source": [
        "learner_clas.freeze_to(-2)\n",
        "learner_clas.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3))"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.290725</td>\n",
              "      <td>0.192228</td>\n",
              "      <td>0.934319</td>\n",
              "      <td>1.211947</td>\n",
              "      <td>03:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.252473</td>\n",
              "      <td>0.193395</td>\n",
              "      <td>0.933498</td>\n",
              "      <td>1.213362</td>\n",
              "      <td>03:11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pFHYZJtsq3F"
      },
      "source": [
        "We can continue to expirment in working backwards but as this is a demo we'll stop here and just unfreeze the whole model and then one last run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "jDFoInmUnZno",
        "outputId": "e3d3b9df-00e3-4c5e-b8ce-140193a933db"
      },
      "source": [
        "learner_clas.unfreeze()\n",
        "learner_clas.fit_one_cycle(1, slice(1e-3/(2.6**4),1e-3))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.212819</td>\n",
              "      <td>0.145079</td>\n",
              "      <td>0.945813</td>\n",
              "      <td>1.156131</td>\n",
              "      <td>03:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.192938</td>\n",
              "      <td>0.138248</td>\n",
              "      <td>0.953202</td>\n",
              "      <td>1.148260</td>\n",
              "      <td>03:45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNKyiv5GtRxa"
      },
      "source": [
        "Lets save our classifier. This model can be loaded and used to classify new data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "pDZmLKr6JJt6",
        "outputId": "c12c3e70-7c88-4154-fa4f-0f5fa9143fbe"
      },
      "source": [
        "interp = fastai.text.all.ClassificationInterpretation.from_learner(learner_clas)\n",
        "interp.plot_confusion_matrix()"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Owu6w3kQndJR",
        "outputId": "0bd7ef2e-ea16-4736-b9d3-777fd493596f"
      },
      "source": [
        "learner_clas.save(\"reports_sector_classifier\")"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('drive/My Drive/Colab Notebooks/files/Reports/models/reports_sector_classifier.pth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "yWPR1h-Snfzf",
        "outputId": "cfe2b709-45ac-4437-8630-194a3a036488"
      },
      "source": [
        "learner_clas.predict(item= \"This service didn't protect people's safety, it negelected to treat people with dignity and smelled funny\")"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('False', tensor(0), tensor([0.9215, 0.0785]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-qDqFG-ZCRL"
      },
      "source": [
        "# Why is this so good\n",
        "For a single text classifier this two step approach might not seem valuable but the ability to focus once on training a single high quality understanding of the language in reports and then reuse that to quickly build effective classifiers scales well.\n",
        "\n",
        "Building tens of classifiers that are generally high perfoming with minimal tuning is not an unachieveable task if we investing in developing a good intial language model. \n",
        "\n",
        "It also means improvements in the language model can improve performance across multiple classifiers, giving us two places we and seek to improve performance. Once in the language model and again in the final classifier.  \n",
        "\n",
        "By using FASTAI all of these steps can be achieved relatively easily with decent performance. "
      ]
    }
  ]
}